# Stabilized GAN Models Training with Kernel-Histogram Transformation and Probability Mass Function Distance
![figure1](https://github.com/Jangwon37/PMF-GAN/assets/99333410/f77ad3c8-bd9e-45a8-9812-fe2c124386d6)

# Abstract
Image generation using generative adversarial networks (GANs) has been extensively researched in recent years. Despite active developments, the chronic issue of training instability in GANs remains unresolved. To alleviate this problem, this study proposes a model named probability mass function GANs (PMF-GAN), which handles the inherent limitation of GANs. The PMF-GAN framework employs kernels, histogram transformation, and probability mass function (PMF) distance for distribution learning. The configuration of PMF-GAN kernel and PMF distance offers flexibility, allowing for optimal settings tailored to datasets and experimental environments. In this study, experiments were conducted using the gaussian kernel across five different distances. The experiments demonstrated that PMF-GAN outperforms the baselines in terms of visual quality and evaluation metrics, such as Inception score and Frechet Inception distance (FID). For example, in the CIFAR-10 dataset, Euclidean-based PMF-GAN applying with 3 bins showed a 21.5% and 32.8% improvement in Inception score and FID, respectively, compared to conventional WGAN. Similarly, in the CelebA dataset with the same settings, the improvements were 16.1% and 28.1%. As a result, this study suggests the possibility of achieving stable traning process of GAN models with modified loss function sturcture, which can be the signficant contribution for the overall enhancement in GAN model training procedure.
